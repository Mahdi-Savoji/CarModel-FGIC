{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":46697,"sourceType":"datasetVersion","datasetId":31559}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom concurrent.futures import ThreadPoolExecutor\n\n# === Helper: Find class name for image ===\ndef find_class_folder(base_dir, filename):\n    for root, _, files in os.walk(base_dir):\n        if filename in files:\n            return os.path.relpath(root, base_dir)\n    return None\n\n# === Load annotations and map class names ===\ndef load_annotations(csv_path, base_img_dir):\n    cols = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class_id']\n    df = pd.read_csv(csv_path, names=cols)\n    tqdm.pandas(desc=\"Mapping class names\")\n    df['class_name'] = df['filename'].progress_apply(lambda x: find_class_folder(base_img_dir, x))\n    return df\n\n# === Process one image: crop, save, and return record ===\ndef process_image(row, src_base_dir, dst_base_dir, dataset_type):\n    try:\n        filename = row['filename']\n        class_name = row['class_name']\n        class_id = row['class_id']\n        xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n\n        src_path = os.path.join(src_base_dir, class_name, filename)\n        dst_dir = os.path.join(dst_base_dir, dataset_type, class_name)\n        os.makedirs(dst_dir, exist_ok=True)\n        dst_path = os.path.join(dst_dir, filename)\n\n        img = cv2.imread(src_path)\n        if img is None:\n            return None\n\n        cropped = img[ymin:ymax, xmin:xmax]\n        cv2.imwrite(dst_path, cropped)\n\n        return {\n            \"path\": f\"{dataset_type}/{class_name}/{filename}\",\n            \"class_id\": class_id,\n            \"class_name\": class_name\n        }\n    except:\n        return None\n\n# === Apply multiprocessing crop ===\ndef save_cropped_dataset(df, src_base_dir, dst_base_dir, dataset_type):\n    results = []\n    with ThreadPoolExecutor() as executor:\n        futures = []\n        for _, row in df.iterrows():\n            futures.append(executor.submit(process_image, row, src_base_dir, dst_base_dir, dataset_type))\n        for f in tqdm(futures, desc=f\"Cropping {dataset_type} images\"):\n            result = f.result()\n            if result:\n                results.append(result)\n    return pd.DataFrame(results)\n\n# === Paths ===\nTRAIN_IMG_DIR = \"/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/train\"\nTEST_IMG_DIR = \"/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/test\"\nANNO_TRAIN = \"/kaggle/input/stanford-car-dataset-by-classes-folder/anno_train.csv\"\nANNO_TEST = \"/kaggle/input/stanford-car-dataset-by-classes-folder/anno_test.csv\"\nOUTPUT_DIR = \"/kaggle/working/cropped_stanford-car-dataset\"\n\n# === Load annotations ===\ntrain_df = load_annotations(ANNO_TRAIN, TRAIN_IMG_DIR)\ntest_df = load_annotations(ANNO_TEST, TEST_IMG_DIR)\n\n# === Save cropped datasets ===\ncropped_train = save_cropped_dataset(train_df, TRAIN_IMG_DIR, OUTPUT_DIR, \"train\")\ncropped_test = save_cropped_dataset(test_df, TEST_IMG_DIR, OUTPUT_DIR, \"test\")\n\n# === Save CSV files ===\ncropped_train.to_csv(os.path.join(OUTPUT_DIR, \"train.csv\"), index=False)\ncropped_test.to_csv(os.path.join(OUTPUT_DIR, \"test.csv\"), index=False)\n\nprint(\"✅ Done! Cropped dataset and CSVs are ready.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T20:00:25.242894Z","iopub.execute_input":"2025-05-02T20:00:25.243162Z","iopub.status.idle":"2025-05-02T20:23:45.266069Z","shell.execute_reply.started":"2025-05-02T20:00:25.243139Z","shell.execute_reply":"2025-05-02T20:23:45.264930Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Mapping class names:   0%|          | 0/8144 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c0e0b221f114f64916ce055d171afd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Mapping class names:   0%|          | 0/8041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c699134347514216b73a402c24bd8dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Cropping train images:   0%|          | 0/8144 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04604ed5849d45b1bb42ea29c71a07d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Cropping test images:   0%|          | 0/8041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f0baaee6004542b339b235d6412c33"}},"metadata":{}},{"name":"stdout","text":"✅ Done! Cropped dataset and CSVs are ready.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import zipfile\nimport os\n\ndef zip_dataset(zip_name, base_dir):\n    zip_path = os.path.join(base_dir, zip_name)\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(base_dir):\n            for file in files:\n                if file == zip_name:\n                    continue  # Don't include the zip file inside itself\n                full_path = os.path.join(root, file)\n                rel_path = os.path.relpath(full_path, base_dir)\n                zipf.write(full_path, arcname=rel_path)\n    print(f\"✅ Dataset zipped at: {zip_path}\")\n\n# Example usage:\nzip_dataset(\"cropped_stanford-car-dataset.zip\", OUTPUT_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T20:25:47.899921Z","iopub.execute_input":"2025-05-02T20:25:47.900297Z","iopub.status.idle":"2025-05-02T20:26:54.355441Z","shell.execute_reply.started":"2025-05-02T20:25:47.900266Z","shell.execute_reply":"2025-05-02T20:26:54.353418Z"}},"outputs":[{"name":"stdout","text":"✅ Dataset zipped at: /kaggle/working/cropped_stanford-car-dataset/cropped_stanford-car-dataset.zip\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport json\nimport shutil\n\n# Define your Kaggle username manually here\nkaggle_username = \"kaggle username\"\n\n# Define dataset metadata\ndataset_name = \"CroppedStanfordCarDataset\"\ndataset_title = \"Cropped Stanford Car Dataset\"\nzip_file_path = \"/kaggle/working/cropped_stanford-car-dataset/cropped_stanford-car-dataset.zip\"\noutput_dir = \"/kaggle/working/kaggle_dataset_upload\"\n\n# Create upload directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# Move ZIP file to upload directory\nshutil.copy(zip_file_path, os.path.join(output_dir, \"cropped_stanford-car-dataset.zip\"))\n\n# Create metadata file for Kaggle dataset\nmetadata = {\n    \"title\": dataset_title,\n    \"id\": f\"{kaggle_username}/{dataset_name}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nwith open(os.path.join(output_dir, \"dataset-metadata.json\"), \"w\") as f:\n    json.dump(metadata, f, indent=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T20:52:39.195688Z","iopub.execute_input":"2025-05-02T20:52:39.196210Z","iopub.status.idle":"2025-05-02T20:52:45.785044Z","shell.execute_reply.started":"2025-05-02T20:52:39.196175Z","shell.execute_reply":"2025-05-02T20:52:45.783710Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import json\nimport os\n\n# Replace with contents of your kaggle.json\nkaggle_token = {\n    \"username\": \"kaggle username\",\n    \"key\": \"kaggle token\"\n}\n\n# Save it to the appropriate location\nos.makedirs(\"/root/.config/kaggle\", exist_ok=True)\nwith open(\"/root/.config/kaggle/kaggle.json\", \"w\") as f:\n    json.dump(kaggle_token, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T20:52:59.654106Z","iopub.execute_input":"2025-05-02T20:52:59.654445Z","iopub.status.idle":"2025-05-02T20:52:59.660946Z","shell.execute_reply.started":"2025-05-02T20:52:59.654417Z","shell.execute_reply":"2025-05-02T20:52:59.659975Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle_dataset_upload --dir-mode zip\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T20:53:00.625328Z","iopub.execute_input":"2025-05-02T20:53:00.625721Z","iopub.status.idle":"2025-05-02T20:53:36.619777Z","shell.execute_reply.started":"2025-05-02T20:53:00.625691Z","shell.execute_reply":"2025-05-02T20:53:36.618757Z"}},"outputs":[{"name":"stdout","text":"Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.config/kaggle/kaggle.json'\nStarting upload for file cropped_stanford-car-dataset.zip\n100%|██████████████████████████████████████| 1.31G/1.31G [00:33<00:00, 42.4MB/s]\nUpload successful: cropped_stanford-car-dataset.zip (1GB)\nYour private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/mahdisavoji/CroppedStanfordCarDataset\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}